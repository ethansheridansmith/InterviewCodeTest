{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4ff8f6",
   "metadata": {},
   "source": [
    "### Step 1.1: Import Libraries\n",
    "We load all necessary Python libraries to work with 3D medical imaging, including file handling, numerical processing, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea3075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports and Setup\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#make plots inline for Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb1d08",
   "metadata": {},
   "source": [
    "### Step 1.2: Define Data Path and Load NIfTI File\n",
    "\n",
    "We load a FLAIR modality MRI volume using nibabel, and convert it into a NumPy array for analysis and visualization. We also extract the affine matrix, which contains spatial information about the image in real-world coordinates (e.g. mm in scanner space).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcc8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample FLAIR file path (can later generalize to load all modalities)\n",
    "sample_id = \"BraTS20_Validation_001\"\n",
    "modality = \"flair\"\n",
    "data_dir = \"../data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData\"\n",
    "\n",
    "# Check if the data directory exists\n",
    "nii_file = os.path.join(data_dir, sample_id, f\"{sample_id}_{modality}.nii\")\n",
    "\n",
    "# Load NIfTI file using nibabel\n",
    "img = nib.load(nii_file)\n",
    "data = img.get_fdata()\n",
    "affine = img.affine\n",
    "\n",
    "# Diagnostics on the file etc. \n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Voxel intensity range: {np.min(data):.2f} to {np.max(data):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c36df1",
   "metadata": {},
   "source": [
    "### Step 1.3: Normalize Intensities to [0, 1]\n",
    "\n",
    "MRI scans can have wildly different intensity ranges depending on the scanner, patient, and sequence. We scale voxel values to the [0, 1] range using min-max normalization, both for interpretability and performance.\n",
    "\n",
    "This step wasn’t something i was struggling with for a while — I had to test multiple workbooks and approaches to find a clean solution. It’s also a good reminder of how data preparation directly affects UX when visualizing or modeling.\n",
    "\n",
    "This step standardizes brightness values, which:\n",
    "- Helps machine learning models generalize better\n",
    "- akes visualizations more comparable across scans\n",
    "- Avoids crashing or freezing from trying to plot extreme intensity spikes (as I discovered when testing on my M1 chip!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_volume(volume):\n",
    "    return (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n",
    "\n",
    "normalized_data = normalize_volume(data)\n",
    "\n",
    "print(f\"Normalized range: {np.min(normalized_data):.2f} to {np.max(normalized_data):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141f5a2",
   "metadata": {},
   "source": [
    "### Step 1.4: Threshold and Subsample\n",
    "\n",
    "We remove low-intensity (near-zero) voxels — these typically correspond to background space (air or scanner padding) — which would otherwise clutter the plot. We also subsample every 2nd voxel along each axis to reduce rendering load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd41311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold to suppress background noise\n",
    "threshold = 0.3 # can see the the tumor on the back right hand side of the data set  !\n",
    "# threshold = 0.1 very thick \n",
    "# threshold = 0.2 seems ideal for this dataset\n",
    "# threshold = 0.5 too minimal visualisation\n",
    "thresholded = normalized_data > threshold\n",
    "\n",
    "# Subsample for fast plotting\n",
    "subsample = (slice(None, None, 2), slice(None, None, 2), slice(None, None, 2))\n",
    "mask = thresholded[subsample]\n",
    "vol = normalized_data[subsample]\n",
    "\n",
    "# Get voxel positions and intensities\n",
    "x, y, z = np.where(mask)\n",
    "intensities = vol[x, y, z]\n",
    "\n",
    "print(f\"Voxels retained after thresholding and subsampling: {len(x)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4240961e",
   "metadata": {},
   "source": [
    "### Step 1.5: Quick 3D Scatter3D Visualization\n",
    "\n",
    "We plot the 3D brain structure using Plotly's Scatter3d, which is fast and lightweight for rendering voxel clouds. Each point corresponds to a voxel above the intensity threshold.\n",
    "\n",
    "You should see the outer contour of the brain and possibly some internal density changes.\n",
    "\n",
    "If nothing shows up or the plot is blank, it likely means the threshold was too high or normalization failed — this plot serves as a real-time check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d076e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter3d(\n",
    "    x=x, y=y, z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1.5,\n",
    "        color=intensities,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.6\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"3D MRI Scan (FLAIR) - {sample_id}\",\n",
    "    scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
    "    margin=dict(l=0, r=0, b=0, t=30)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cbdce",
   "metadata": {},
   "source": [
    "### Final Summary (Markdown Cell for End of Section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3f369",
   "metadata": {},
   "source": [
    "In this section, I built a basic 3D brain visualization pipeline using a FLAIR scan from the BraTS2020 dataset. I loaded and normalized the data, removed low-intensity voxels, and created a sparse 3D visualization using Plotly. This not only helps validate data quality but sets the foundation for deeper analysis and segmentation modeling.\n",
    "In practice, this step reveals challenges like rendering speed, image noise, and voxel range variability — all of which are essential considerations when building deployable medical AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece3482",
   "metadata": {},
   "source": [
    "# EDA\n",
    "### 2.1: Load All Modalities for One Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9618698",
   "metadata": {},
   "source": [
    "Each modality captures different tissue characteristics, so visualizing them together allows:\n",
    "\n",
    "- Better anatomical understanding of the brain\n",
    "- Insights into how tumors appear across contrasts\n",
    "- Groundwork for multi-channel model input\n",
    "\n",
    "Radiologists use multiple modalities because tumors behave differently across contrasts. For instance:\n",
    "\n",
    "- T1 – baseline structural scan\n",
    "- T1ce enhances active tumor regions\n",
    "- FLAIR highlights tumor surroundings (edema)\n",
    "- T2 is sensitive to fluid accumulation\n",
    "\n",
    "Understanding these distinctions helps model design (e.g., stacking inputs across modalities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bef08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all 4 modalities for a sample subject\n",
    "modalities = ['t1', 't1ce', 't2', 'flair']\n",
    "sample_id = \"BraTS20_Validation_001\"\n",
    "data_dir = \"../data/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData\"\n",
    "\n",
    "def load_modalities(subject_id, modalities):\n",
    "    subject_path = os.path.join(data_dir, subject_id)\n",
    "    volumes = {}\n",
    "    for mod in modalities:\n",
    "        path = os.path.join(subject_path, f\"{subject_id}_{mod}.nii\")\n",
    "        img = nib.load(path)\n",
    "        volumes[mod] = img.get_fdata()\n",
    "    return volumes\n",
    "\n",
    "volumes = load_modalities(sample_id, modalities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intensity distributions to understand modality differences\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "for i, mod in enumerate(modalities):\n",
    "    data = volumes[mod]\n",
    "    axes[i].hist(data[data > 0].ravel(), bins=100, color='steelblue')\n",
    "    axes[i].set_title(f\"{mod.upper()} Histogram\")\n",
    "    axes[i].set_xlabel(\"Intensity\")\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53dbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show middle slice along 3 axes for each modality\n",
    "def show_slices(volume, title, cmap='gray'):\n",
    "    mid_slices = [s//2 for s in volume.shape]\n",
    "    axial = volume[:, :, mid_slices[2]]\n",
    "    coronal = volume[:, mid_slices[1], :]\n",
    "    sagittal = volume[mid_slices[0], :, :]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].imshow(np.rot90(axial), cmap=cmap)\n",
    "    axes[0].set_title('Axial')\n",
    "    axes[1].imshow(np.rot90(coronal), cmap=cmap)\n",
    "    axes[1].set_title('Coronal')\n",
    "    axes[2].imshow(np.rot90(sagittal), cmap=cmap)\n",
    "    axes[2].set_title('Sagittal')\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display for each modality\n",
    "for mod in modalities:\n",
    "    show_slices(volumes[mod], f\"{mod.upper()} Slices\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
